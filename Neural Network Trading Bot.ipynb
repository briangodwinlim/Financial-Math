{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Trading Bot \n",
    "\n",
    "Using historical stock data, we build a LSTM model to classify whether to buy, sell, or hold.\n",
    "\n",
    "Note: this project is for educational purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NxHt59s_VZK-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                      # Pandas\n",
    "import numpy as np                       # Numpy\n",
    "import ta                                # Technical analysis\n",
    "from psequant import get_pse_data        # Get Philippine Stock Exchange (PSE) data\n",
    "import warnings                          # Ignore warnings\n",
    "import matplotlib.pyplot as plt          # Plotting\n",
    "import tensorflow as tf                  # Tensorflow\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ta(df, rescale = True):\n",
    "    \"\"\" Add commonly used technical indicators to features using the TA library\"\"\"\n",
    "\n",
    "    df['EMA10'] = ta.trend.EMAIndicator(df['close'], window = 10).ema_indicator()\n",
    "    df['EMA20'] = ta.trend.EMAIndicator(df['close'], window = 20).ema_indicator()\n",
    "    df['EMA50'] = ta.trend.EMAIndicator(df['close'], window = 50).ema_indicator()\n",
    "    df['EMA100'] = ta.trend.EMAIndicator(df['close'], window = 100).ema_indicator()\n",
    "\n",
    "    df['MA10'] = ta.trend.SMAIndicator(df['close'], window = 10).sma_indicator()\n",
    "    df['MA20'] = ta.trend.SMAIndicator(df['close'], window = 20).sma_indicator()\n",
    "    df['MA50'] = ta.trend.SMAIndicator(df['close'], window = 50).sma_indicator()\n",
    "    df['MA100'] = ta.trend.SMAIndicator(df['close'], window = 100).sma_indicator()\n",
    "\n",
    "    df['ADX'] = ta.trend.ADXIndicator(df['high'], df['low'], df['close']).adx()\n",
    "\n",
    "    macd_hist = ta.trend.MACD(df['close'])\n",
    "    df['MACD Diff'] = macd_hist.macd_diff()\n",
    "    df['MACD Line'] = macd_hist.macd()\n",
    "    df['Signal Line'] = macd_hist.macd_signal()\n",
    "\n",
    "    df['RSI'] = ta.momentum.rsi(df['close'])\n",
    "    \n",
    "    if rescale:\n",
    "        df[['EMA10', 'EMA20', 'EMA50', 'EMA100', \n",
    "            'MA10', 'MA20', 'MA50', 'MA100', \n",
    "            'close', 'open', 'high', 'low']] /= 1000\n",
    "        df[['ADX', 'RSI']] /= 100\n",
    "        df[['MACD Diff', 'MACD Line', 'Signal Line']] /= 10\n",
    "        df['value'] /= 100000000\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(df, lag = 15, threshold = 1.5):    \n",
    "    \"\"\" Get the classification of each candle stick based on next close.\n",
    "        We want to classify breakouts (Buy), breakdowns (Sell), and consolidations (Hold).\n",
    "        We base the classification on some support and resistance lines.\n",
    "    \"\"\"\n",
    "\n",
    "    df['upper'] = df.apply(lambda df: max(df['close'], df['open']), axis = 1)\n",
    "    df['lower'] = df.apply(lambda df: min(df['close'], df['open']), axis = 1)\n",
    "    df['max upper'] = df['upper']\n",
    "    df['min lower'] = df['lower']\n",
    "\n",
    "    for i in range(1, lag):\n",
    "        df[f'UB{i}'] = df['upper'].shift(i)\n",
    "        df[f'LB{i}'] = df['lower'].shift(i)\n",
    "        df['max upper'] = df.apply(lambda df: max(df['max upper'], df[f'UB{i}']), axis = 1)\n",
    "        df['min lower'] = df.apply(lambda df: min(df['min lower'], df[f'LB{i}']), axis = 1)\n",
    "        df.drop([f'UB{i}', f'LB{i}'], axis = 1, inplace = True)\n",
    "\n",
    "    df['next_close'] = df['close'].shift(-1)\n",
    "    \n",
    "    df['breakout'] = df.apply(lambda df: \n",
    "            1 if df['next_close'] > (1 + threshold / 100) * df['max upper'] else 0, \n",
    "            axis = 1)\n",
    "    df['breakdown'] = df.apply(lambda df:\n",
    "            1 if df['next_close'] < (1 - threshold / 100) * df['min lower'] else 0,\n",
    "            axis = 1)\n",
    "    df['consolidating'] = 1 - df['breakout'] - df['breakdown']\n",
    "\n",
    "    df.dropna(inplace = True)\n",
    "\n",
    "    return df.drop(['next_close', 'upper', 'lower', 'max upper', 'min lower'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_io(df, lag = 15):\n",
    "    input = []\n",
    "    output = [] \n",
    "    \n",
    "    for index in range(lag,df.shape[0]):\n",
    "        input.append(\n",
    "            np.array(\n",
    "                df.drop(['consolidating', 'breakout', 'breakdown'], axis = 1)[index - lag : index]\n",
    "            ).reshape(1,-1)\n",
    "        )\n",
    "        output.append(\n",
    "            np.array(\n",
    "                df[['consolidating', 'breakout', 'breakdown']][index - 1 : index]\n",
    "            ).reshape(1,-1)\n",
    "        )\n",
    "\n",
    "    return np.array(input), np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splitted_data(df, split = 100):\n",
    "    df = get_ta(df)\n",
    "    df = get_classification(df)\n",
    "    if 'dt' in df.columns:\n",
    "        df.drop('dt', axis = 1, inplace = True)\n",
    "    input, output = split_io(df)\n",
    "    \n",
    "    train_input = input[:-split]\n",
    "    train_output = output[:-split]\n",
    "    test_input = input[-split:]\n",
    "    test_output = output[-split:]\n",
    "    \n",
    "    return train_input, train_output, test_input, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(model_fit):\n",
    "    plt.plot(model_fit.history['accuracy'])\n",
    "    plt.plot(model_fit.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc = 'upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(model_fit.history['loss'])\n",
    "    plt.plot(model_fit.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `get_pse_data`, we get historical stock data. We then split the data into training and test data using `get_splitted_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock table exists!\n",
      "Reading stock_table.csv ...\n"
     ]
    }
   ],
   "source": [
    "df = get_pse_data('JFC', '2000-01-01', '2021-11-30')\n",
    "train_input, train_output, test_input, test_output = get_splitted_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built an LSTM model with two LSTM layers and three dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 1, 200)            296800    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1, 200)            240800    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 100)            20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 100)            10100     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 3)              303       \n",
      "=================================================================\n",
      "Total params: 568,103\n",
      "Trainable params: 568,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(window_size, return_sequences = True), \n",
    "            input_shape = train_input[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(window_size, return_sequences = True)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = window_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = window_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', \n",
    "        metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "66/66 [==============================] - 12s 46ms/step - loss: 0.4363 - accuracy: 0.9311 - val_loss: 0.4313 - val_accuracy: 0.8918\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 2s 33ms/step - loss: 0.2941 - accuracy: 0.9368 - val_loss: 0.4552 - val_accuracy: 0.8918\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2973 - accuracy: 0.9368 - val_loss: 0.4376 - val_accuracy: 0.8918\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2871 - accuracy: 0.9368 - val_loss: 0.4667 - val_accuracy: 0.8918\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.2845 - accuracy: 0.9368 - val_loss: 0.4313 - val_accuracy: 0.8918\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.2870 - accuracy: 0.9368 - val_loss: 0.4467 - val_accuracy: 0.8918\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2838 - accuracy: 0.9368 - val_loss: 0.4330 - val_accuracy: 0.8918\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.2873 - accuracy: 0.9368 - val_loss: 0.4269 - val_accuracy: 0.8918\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.2854 - accuracy: 0.9368 - val_loss: 0.4323 - val_accuracy: 0.8918\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2805 - accuracy: 0.9368 - val_loss: 0.4301 - val_accuracy: 0.8918\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2788 - accuracy: 0.9368 - val_loss: 0.4623 - val_accuracy: 0.8918\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2835 - accuracy: 0.9368 - val_loss: 0.4438 - val_accuracy: 0.8918\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.2850 - accuracy: 0.9368 - val_loss: 0.4420 - val_accuracy: 0.8918\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2811 - accuracy: 0.9368 - val_loss: 0.4603 - val_accuracy: 0.8918\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.2733 - accuracy: 0.9368 - val_loss: 0.4343 - val_accuracy: 0.8918\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2758 - accuracy: 0.9368 - val_loss: 0.5016 - val_accuracy: 0.8918\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.2817 - accuracy: 0.9368 - val_loss: 0.4502 - val_accuracy: 0.8918\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2721 - accuracy: 0.9368 - val_loss: 0.4351 - val_accuracy: 0.8918\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.2702 - accuracy: 0.9368 - val_loss: 0.4216 - val_accuracy: 0.8918\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2625 - accuracy: 0.9368 - val_loss: 0.4562 - val_accuracy: 0.8918\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2633 - accuracy: 0.9368 - val_loss: 0.4135 - val_accuracy: 0.8918\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.2605 - accuracy: 0.9368 - val_loss: 0.4574 - val_accuracy: 0.8918\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2565 - accuracy: 0.9368 - val_loss: 0.4265 - val_accuracy: 0.8918\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.2607 - accuracy: 0.9368 - val_loss: 0.4508 - val_accuracy: 0.8918\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.2572 - accuracy: 0.9368 - val_loss: 0.4147 - val_accuracy: 0.8918\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.2569 - accuracy: 0.9368 - val_loss: 0.4058 - val_accuracy: 0.8918\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.2475 - accuracy: 0.9368 - val_loss: 0.4441 - val_accuracy: 0.8918\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2452 - accuracy: 0.9368 - val_loss: 0.4434 - val_accuracy: 0.8918\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2456 - accuracy: 0.9368 - val_loss: 0.4539 - val_accuracy: 0.8918\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2411 - accuracy: 0.9368 - val_loss: 0.4698 - val_accuracy: 0.8918\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.2475 - accuracy: 0.9368 - val_loss: 0.4524 - val_accuracy: 0.8918\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2387 - accuracy: 0.9368 - val_loss: 0.4505 - val_accuracy: 0.8918\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.2315 - accuracy: 0.9368 - val_loss: 0.5453 - val_accuracy: 0.8918\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2303 - accuracy: 0.9368 - val_loss: 0.4736 - val_accuracy: 0.8918\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2361 - accuracy: 0.9368 - val_loss: 0.5344 - val_accuracy: 0.8918\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2403 - accuracy: 0.9368 - val_loss: 0.4819 - val_accuracy: 0.8918\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.2300 - accuracy: 0.9368 - val_loss: 0.4549 - val_accuracy: 0.8918\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.2280 - accuracy: 0.9368 - val_loss: 0.5471 - val_accuracy: 0.8918\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.2194 - accuracy: 0.9368 - val_loss: 0.6191 - val_accuracy: 0.8918\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2200 - accuracy: 0.9368 - val_loss: 0.6461 - val_accuracy: 0.8918\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 4s 62ms/step - loss: 0.2188 - accuracy: 0.9368 - val_loss: 0.6021 - val_accuracy: 0.8918\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 5s 72ms/step - loss: 0.2150 - accuracy: 0.9368 - val_loss: 0.5860 - val_accuracy: 0.8918\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 5s 72ms/step - loss: 0.2220 - accuracy: 0.9368 - val_loss: 0.7220 - val_accuracy: 0.8918\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 5s 70ms/step - loss: 0.2117 - accuracy: 0.9368 - val_loss: 0.6282 - val_accuracy: 0.8918\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 4s 68ms/step - loss: 0.2157 - accuracy: 0.9368 - val_loss: 0.6379 - val_accuracy: 0.8918\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 5s 72ms/step - loss: 0.2067 - accuracy: 0.9368 - val_loss: 0.8090 - val_accuracy: 0.8918\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 3s 47ms/step - loss: 0.2054 - accuracy: 0.9368 - val_loss: 0.7364 - val_accuracy: 0.8918\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.2084 - accuracy: 0.9368 - val_loss: 0.8963 - val_accuracy: 0.8918\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1946 - accuracy: 0.9368 - val_loss: 0.7889 - val_accuracy: 0.8918\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.2042 - accuracy: 0.9368 - val_loss: 0.7774 - val_accuracy: 0.8918\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1995 - accuracy: 0.9378 - val_loss: 0.8349 - val_accuracy: 0.8918\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1980 - accuracy: 0.9383 - val_loss: 0.8371 - val_accuracy: 0.8918\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1879 - accuracy: 0.9383 - val_loss: 0.8557 - val_accuracy: 0.8899\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1926 - accuracy: 0.9378 - val_loss: 0.8515 - val_accuracy: 0.8918\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1881 - accuracy: 0.9387 - val_loss: 0.9141 - val_accuracy: 0.8899\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1918 - accuracy: 0.9397 - val_loss: 0.8582 - val_accuracy: 0.8899\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1793 - accuracy: 0.9387 - val_loss: 1.0949 - val_accuracy: 0.8899\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1798 - accuracy: 0.9402 - val_loss: 1.1160 - val_accuracy: 0.8918\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1723 - accuracy: 0.9387 - val_loss: 1.1930 - val_accuracy: 0.8899\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1726 - accuracy: 0.9416 - val_loss: 1.2829 - val_accuracy: 0.8937\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1823 - accuracy: 0.9402 - val_loss: 1.1261 - val_accuracy: 0.8918\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1665 - accuracy: 0.9397 - val_loss: 1.1196 - val_accuracy: 0.8918\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1702 - accuracy: 0.9392 - val_loss: 1.3330 - val_accuracy: 0.8918\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1773 - accuracy: 0.9383 - val_loss: 1.3699 - val_accuracy: 0.8918\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1677 - accuracy: 0.9425 - val_loss: 1.3517 - val_accuracy: 0.8899\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.1561 - accuracy: 0.9402 - val_loss: 1.4742 - val_accuracy: 0.8918\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1607 - accuracy: 0.9425 - val_loss: 1.3217 - val_accuracy: 0.8918\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1571 - accuracy: 0.9430 - val_loss: 1.3308 - val_accuracy: 0.8899\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.1631 - accuracy: 0.9378 - val_loss: 1.5989 - val_accuracy: 0.8899\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.1674 - accuracy: 0.9411 - val_loss: 1.8608 - val_accuracy: 0.8918\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.1610 - accuracy: 0.9425 - val_loss: 1.4033 - val_accuracy: 0.8880\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1685 - accuracy: 0.9406 - val_loss: 1.2949 - val_accuracy: 0.8918\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1558 - accuracy: 0.9421 - val_loss: 1.7099 - val_accuracy: 0.8937\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.1567 - accuracy: 0.9449 - val_loss: 1.7818 - val_accuracy: 0.8918\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1518 - accuracy: 0.9402 - val_loss: 1.5709 - val_accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1641 - accuracy: 0.9416 - val_loss: 1.6613 - val_accuracy: 0.8918\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1558 - accuracy: 0.9406 - val_loss: 1.6717 - val_accuracy: 0.8899\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1559 - accuracy: 0.9416 - val_loss: 1.7289 - val_accuracy: 0.8880\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1512 - accuracy: 0.9440 - val_loss: 1.4252 - val_accuracy: 0.8899\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1500 - accuracy: 0.9425 - val_loss: 1.5042 - val_accuracy: 0.8899\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 3s 38ms/step - loss: 0.1403 - accuracy: 0.9425 - val_loss: 1.7777 - val_accuracy: 0.8937\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1432 - accuracy: 0.9421 - val_loss: 1.6889 - val_accuracy: 0.8767\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1420 - accuracy: 0.9444 - val_loss: 2.0703 - val_accuracy: 0.8918\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1385 - accuracy: 0.9449 - val_loss: 1.8392 - val_accuracy: 0.8710\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1471 - accuracy: 0.9482 - val_loss: 1.8315 - val_accuracy: 0.8861\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1349 - accuracy: 0.9482 - val_loss: 1.8062 - val_accuracy: 0.8861\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1337 - accuracy: 0.9459 - val_loss: 2.1846 - val_accuracy: 0.8805\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1457 - accuracy: 0.9435 - val_loss: 1.7934 - val_accuracy: 0.8918\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 2s 37ms/step - loss: 0.1404 - accuracy: 0.9435 - val_loss: 1.7276 - val_accuracy: 0.8899\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.1522 - accuracy: 0.9425 - val_loss: 2.0437 - val_accuracy: 0.8899\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 2s 34ms/step - loss: 0.1354 - accuracy: 0.9430 - val_loss: 1.7227 - val_accuracy: 0.8824\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1316 - accuracy: 0.9473 - val_loss: 1.7630 - val_accuracy: 0.8843\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1359 - accuracy: 0.9478 - val_loss: 1.7940 - val_accuracy: 0.8824\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1272 - accuracy: 0.9468 - val_loss: 2.0737 - val_accuracy: 0.8899\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1265 - accuracy: 0.9468 - val_loss: 2.0327 - val_accuracy: 0.8596\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1279 - accuracy: 0.9440 - val_loss: 2.0499 - val_accuracy: 0.8786\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 0.1236 - accuracy: 0.9511 - val_loss: 2.4812 - val_accuracy: 0.8805\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 2s 38ms/step - loss: 0.1171 - accuracy: 0.9525 - val_loss: 2.4976 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 3s 39ms/step - loss: 0.1146 - accuracy: 0.9577 - val_loss: 2.6436 - val_accuracy: 0.8786\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 2s 36ms/step - loss: 0.1139 - accuracy: 0.9539 - val_loss: 2.7173 - val_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_input, train_output, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the performance of our model against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_input)\n",
    "m = CategoricalAccuracy()\n",
    "m.update_state(test_output, predictions)\n",
    "m.result().numpy()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Trading Bot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

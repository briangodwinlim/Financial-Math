{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value at Risk - Bonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Functional Implementation\n",
    "The specifications of the functions are specified in the succeeding code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta \n",
    "from scipy.stats import norm\n",
    "from statistics import NormalDist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_return_bonds(df):\n",
    "    \"\"\" Computes the log return of bonds \"\"\"\n",
    "    \n",
    "    return np.log(df[\"Yield\"]/df[\"previous\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_bonds(df,d,ewma_par):\n",
    "    \"\"\" Computes the weights of EWMA \"\"\"\n",
    "    \n",
    "    count_returns = len(df[\"Yield\"])-d\n",
    "    weight_lst = [(1 - ewma_par) * (ewma_par**i) for i in range(count_returns)]\n",
    "    df[\"weight\"] = pd.Series(weight_lst)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interp(t,x,y):\n",
    "    \"\"\" Custom linear interpolation \"\"\"\n",
    "    \n",
    "    m = (y[1]-y[0])/(x[1]-x[0])\n",
    "    y = y[0] + m*(t-x[0])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tenor(start_date, end_date):\n",
    "    \"\"\" Computes the tenor of the bond \"\"\"\n",
    "    \n",
    "    day_count = (end_date - start_date).days\n",
    "    tenor = day_count / 360.0\n",
    "    return tenor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bond_info(\n",
    "    today, mat, FV, coupon_rate, coupon_freq, y \n",
    "):\n",
    "    \"\"\" Calculates the (clean) price, modified duration, and DV01 of a coupon-bearing bond [not zero-coupon bond] \n",
    "        today using the given continuously compunded market yield. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    today : datetime\n",
    "        the date today in '%Y-%m-%d' format\n",
    "    mat : datetime\n",
    "        the maturity date in '%Y-%m-%d' format\n",
    "    FV : float\n",
    "        the face value or par value, FV in units of currency\n",
    "    coupon_rate : float\n",
    "        (annual) coupon_rate\n",
    "    coupon_freq : int\n",
    "        the number of times coupon interest is paid in one year\n",
    "    y : float\n",
    "        market yield continuously compounded\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        [Price,Modified Duration,DV01]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the coupon\n",
    "    coupon = (coupon_rate * FV) / coupon_freq\n",
    "    \n",
    "    today = dt.datetime.strptime(today, '%Y-%m-%d')\n",
    "    mat_date = dt.datetime.strptime(mat, '%Y-%m-%d') \n",
    "    \n",
    "    # Create list of coupon dates\n",
    "    # Currently only works for annual coupon payments\n",
    "    coupon_dates = []\n",
    "    coupon_date = mat_date\n",
    "    \n",
    "    while today < coupon_date:\n",
    "        if coupon_freq==1:# annual\n",
    "            coupon_dates.append(coupon_date)\n",
    "            coupon_date = coupon_date.replace(year=coupon_date.year - 1) \n",
    "\n",
    "        else:\n",
    "            coupon_dates.append(coupon_date)\n",
    "            coupon_date = coupon_date - relativedelta(months=int(12/coupon_freq))           \n",
    "    \n",
    "    # Arrange coupon_dates in increasing order of dates\n",
    "    coupon_dates = coupon_dates[::-1]\n",
    "    \n",
    "    # Create a dataframe of payment schedules\n",
    "    pmt_df = pd.DataFrame({'coupon_dates':coupon_dates})\n",
    "    \n",
    "    pmt_df[\"t\"] = [get_tenor(today, t) for t in pmt_df['coupon_dates']]\n",
    "    \n",
    "    pmt_df[\"cf\"] = coupon\n",
    "    pmt_df.loc[len(coupon_dates)-1,\"cf\"] += FV\n",
    "    \n",
    "    pmt_df[\"df\"] = np.exp(-pmt_df[\"t\"] * y)\n",
    "    \n",
    "    pmt_df[\"pv\"] = pmt_df[\"cf\"] * pmt_df[\"df\"]\n",
    "    \n",
    "    pmt_df[\"mod_dur\"] = pmt_df[\"t\"] * pmt_df[\"pv\"] / pmt_df[\"pv\"].sum()\n",
    "\n",
    "    Price = pmt_df[\"pv\"].sum()\n",
    "    Modified_Duration = pmt_df[\"mod_dur\"].sum()\n",
    "    DV01 = Price * Modified_Duration / 100**2\n",
    "    \n",
    "    return [Price, Modified_Duration, DV01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undiversified_VaR_delta_normal_bonds(    \n",
    "    df_lst, N_lst, d, p, \n",
    "    ewma_par_lst=None\n",
    "):\n",
    "    \"\"\" Returns the undiversified d-day p% VaR of a portfolio of bonds using Delta Normal Approach.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lst : list of pandas.DataFrame\n",
    "        each df has two columns: (1) Date [str] and (2) Yield [float]\n",
    "        assumes the dates are arranged from newest to oldest, and the date today is the date on the first row\n",
    "        asssumes that all dfs have the same ordered list of dates\n",
    "        there is one df per currency in the portfolio\n",
    "    N_lst : list (of float)\n",
    "        N_i = NV01 for ith bond (order should be the same as the order in df_lst)\n",
    "    d : int\n",
    "        the value to be used in calculating the d-day VaR (e.g. 1-day, 5-day)\n",
    "    p : int\n",
    "        the value to be used in calculating the p% VaR (e.g. 99, 95)\n",
    "    ewma_par_lst : list (of float)\n",
    "        ewma_par_i = the value of the lambda parameter in an exponentially-weighted moving average model \n",
    "        for ith bond (order should be the same as the order in df_lst) \n",
    "        assumes the value is in range (0,1)\n",
    "        assumes there is no None value in the list\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float \n",
    "        undiversified d-day p% VaR of a portfolio of bonds using Delta Normal Approach\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize return value \n",
    "    VaR = 0 \n",
    "    \n",
    "    # Process each df in df_lst\n",
    "    for i in range(len(df_lst)): \n",
    "        \n",
    "        # Get the closing yield\n",
    "        y0 = df_lst[i].loc[0,\"Yield\"]/100 \n",
    "                \n",
    "        # Get the return\n",
    "        df_lst[i][\"previous\"] = df_lst[i][\"Yield\"].shift(-d)\n",
    "        df_lst[i][\"return\"] = df_lst[i].apply(get_return_bonds,axis=1)     \n",
    "        \n",
    "        if ewma_par_lst:\n",
    "            # Solve for the weights and compute the standard deviation\n",
    "            df_lst[i] = get_weights_bonds(df_lst[i],d,ewma_par_lst[i])\n",
    "            sigma = np.sqrt(np.nansum((df_lst[i][\"return\"]**2) * df_lst[i][\"weight\"]))\n",
    "            \n",
    "        else:\n",
    "            # Get the standard deviation\n",
    "            sigma = df_lst[i][\"return\"].std() \n",
    "        \n",
    "        quantile = NormalDist().inv_cdf(p/100)\n",
    "        \n",
    "        VaR += 10000 * y0 * N_lst[i] * sigma * quantile\n",
    "    \n",
    "    return VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversified_VaR_delta_normal_bonds(\n",
    "    df_lst, N_lst, d, p, \n",
    "    ewma_par_lst=None,\n",
    "    covar_ewma_par_mat=None\n",
    "):\n",
    "    \"\"\" Returns the diversified d-day p% VaR of a portfolio of bonds using Delta Normal Approach.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lst : list of pandas.DataFrame\n",
    "        each df has two columns: (1) Date [str] and (2) Yield [float]\n",
    "        assumes the dates are arranged from newest to oldest, and the date today is the date on the first row\n",
    "        asssumes that all dfs have the same ordered list of dates\n",
    "        there is one df per currency in the portfolio\n",
    "    N_lst : list (of int)\n",
    "        N_i = NV01 for ith bond (order should be the same as the order in df_lst)\n",
    "    d : int\n",
    "        the value to be used in calculating the d-day VaR (e.g. 1-day, 5-day)\n",
    "    p : int\n",
    "        the value to be used in calculating the p% VaR (e.g. 99, 95)\n",
    "    ewma_par_lst : list (of float)\n",
    "        ewma_par_i = the value of the lambda parameter in an exponentially-weighted moving average model \n",
    "        for ith bond (order should be the same as the order in df_lst) \n",
    "        assumes the value is in range (0,1)\n",
    "        assumes there is no None value in the list\n",
    "    covar_ewma_par_mat : array of array\n",
    "        covar_ewma_par_mat[i][j] = the EWMA decay parameter for the covariance of the returns of currency i and j\n",
    "        this matrix only has value if EWMA will be used\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        diversified d-day p% VaR of a portfolio of bonds using Delta Normal Approach\n",
    "    \"\"\"\n",
    "        \n",
    "    # Initialize arrays\n",
    "    a = [0 for i in range(len(df_lst))] # alpha vector\n",
    "    return_lst = [0 for i in range(len(df_lst))] # array of returns\n",
    "    \n",
    "    # Process each df in df_lst\n",
    "    for i in range(len(df_lst)):\n",
    "        \n",
    "        # Compute a_i\n",
    "        a[i] = -10000 * N_lst[i] * df_lst[i].loc[0,\"Yield\"]/100\n",
    "    \n",
    "        # Get the returns\n",
    "        df_lst[i][\"previous\"] = df_lst[i][\"Yield\"].shift(-d)\n",
    "        df_lst[i][\"return\"] = df_lst[i].apply(get_return_bonds,axis=1)   \n",
    "        \n",
    "        # Append the current list of return to return_lst\n",
    "        return_lst[i] = df_lst[i][\"return\"][:-d]\n",
    "    \n",
    "    # Convert a to a numpy array\n",
    "    a = np.array(a)\n",
    "\n",
    "    if ewma_par_lst:\n",
    "        # Initialize Capital Sigma (Covariance Matrix)\n",
    "        SIGMA = [[0 for i in range(len(df_lst))] for j in range(len(df_lst))]\n",
    "        \n",
    "        # Process diagonals (Variance)\n",
    "        for i in range(len(df_lst)):\n",
    "            df_lst[i] = get_weights_bonds(df_lst[i],d,ewma_par_lst[i])\n",
    "            SIGMA[i][i] = np.nansum((df_lst[i][\"return\"]**2) * df_lst[i][\"weight\"])\n",
    "        \n",
    "        # Process off-diagonals (Covariance)\n",
    "        df_len = len(df_lst[0][\"Yield\"])-d\n",
    "        for i in range(len(df_lst)):\n",
    "            for j in range(i+1,len(df_lst)):\n",
    "                weights = np.array([(1-covar_ewma_par_mat[i][j])*(covar_ewma_par_mat[i][j]**k) for k in range(df_len)])\n",
    "                tmp = df_lst[i][\"return\"] * df_lst[j][\"return\"]\n",
    "                cov_ij = np.nansum(tmp[:-d] * weights)\n",
    "                SIGMA[i][j] = SIGMA[j][i] = cov_ij\n",
    "\n",
    "    else:\n",
    "        # Get the Covariance Matrix\n",
    "        SIGMA = np.cov(return_lst)\n",
    "    \n",
    "    # Compute the standard deviation of the portfolio\n",
    "    sigma = np.sqrt(np.dot(a.T,np.dot(SIGMA,a)))\n",
    "        \n",
    "    quantile = NormalDist().inv_cdf(p/100)\n",
    "    \n",
    "    VaR = sigma * quantile\n",
    "        \n",
    "    return VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VaR_hs_bonds(\n",
    "    zero_rate_data,today, mat, FV, coupon_rate, coupon_freq, d, p\n",
    "):\n",
    "    \"\"\" Returns the d-day p% VaR of a bond using Historical Simulation Approach.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    zero_rate_data : pandas.DataFrame\n",
    "        the historical zero rates for the benchmark tenors\n",
    "    today : datetime\n",
    "        the date today in '%Y-%m-%d' format\n",
    "    mat : datetime\n",
    "        the maturity date in '%Y-%m-%d' format\n",
    "    FV : float\n",
    "        the face value or par value, FV in units of currency\n",
    "    coupon_rate : float\n",
    "        (annual) coupon_rate\n",
    "    coupon_freq : int\n",
    "        the number of times coupon interest is paid in one year\n",
    "    d : int\n",
    "        the value to be used in calculating the d-day VaR (e.g. 1-day, 5-day)\n",
    "    p : int\n",
    "        the value to be used in calculating the p% VaR (e.g. 99, 95)\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        d-day p% VaR of a bond using Historical Simulation Approach    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create empty dictionary for renaming\n",
    "    rename_dict = {}\n",
    "    \n",
    "    # Create empty list for storing tenors of benchmark\n",
    "    tenor = []\n",
    "    \n",
    "    # Process the columns\n",
    "    for i in zero_rate_data.columns:\n",
    "        if len(str(i).split(\"-\")) == 2:\n",
    "            [a,b] = str(i).split(\"-\")\n",
    "            a = int(a)\n",
    "            if b == \"Month\":\n",
    "                rename_dict[i] = a/12\n",
    "                tenor.append(a/12)\n",
    "            elif b == \"Year\":\n",
    "                rename_dict[i] = a\n",
    "                tenor.append(a)\n",
    "                \n",
    "    # Convert the labels to floats\n",
    "    zero_rate_data.rename(rename_dict,axis=1,inplace=True)\n",
    "        \n",
    "    # Compute the coupon\n",
    "    coupon = (coupon_rate * FV) / coupon_freq\n",
    "    \n",
    "    today = dt.datetime.strptime(today, '%Y-%m-%d')\n",
    "    mat_date = dt.datetime.strptime(mat, '%Y-%m-%d') \n",
    "    \n",
    "    # Create list of coupon dates\n",
    "    # Currently only works for annual coupon payments\n",
    "    coupon_dates = []\n",
    "    coupon_date = mat_date\n",
    "    \n",
    "    while today < coupon_date:\n",
    "        if coupon_freq==1:# annual\n",
    "            coupon_dates.append(coupon_date)\n",
    "            coupon_date = coupon_date.replace(year=coupon_date.year - 1) \n",
    "\n",
    "        else:\n",
    "            coupon_dates.append(coupon_date)\n",
    "            coupon_date = coupon_date - relativedelta(months=int(12/coupon_freq))\n",
    "    \n",
    "    # Arrange coupon_dates in increasing order of dates\n",
    "    coupon_dates = coupon_dates[::-1]\n",
    "    \n",
    "    # Create a dataframe of payment schedules\n",
    "    pmt_df = pd.DataFrame({'coupon_dates':coupon_dates})\n",
    "    \n",
    "    pmt_df[\"t\"] = [get_tenor(today, t) for t in pmt_df['coupon_dates']]\n",
    "    \n",
    "    pmt_df[\"cf\"] = coupon\n",
    "    pmt_df.loc[len(coupon_dates)-1,\"cf\"] += FV\n",
    "    \n",
    "    for t in pmt_df[\"t\"]:\n",
    "        idx = 0\n",
    "        \n",
    "        # Get the two nearest tenors from the benchmark data\n",
    "        while tenor[idx] < t and idx < len(tenor):\n",
    "            idx += 1\n",
    "        \n",
    "        # Linearly interpolate to get the desired tenor\n",
    "        zero_rate_data[t] = linear_interp(t, [tenor[idx],tenor[idx-1]],\n",
    "                                           [zero_rate_data[tenor[idx]],zero_rate_data[tenor[idx-1]]] )\n",
    "\n",
    "    # Generate the DataFrames needed\n",
    "    possible_returns = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"][:-d]})\n",
    "    possible_zero_rate = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"][:-d]})\n",
    "    possible_df = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"][:-d]})\n",
    "    possible_prices = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"][:-d],\"Price\":0})\n",
    "        \n",
    "    for t in pmt_df[\"t\"]:\n",
    "        # Create a temporary DataFrame\n",
    "        tmp_df = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"]})\n",
    "        \n",
    "        # Copy the Yield for tenor t\n",
    "        tmp_df[\"Yield\"] = zero_rate_data[t]\n",
    "        \n",
    "        # Get the returns\n",
    "        tmp_df[\"previous\"] = tmp_df[\"Yield\"].shift(-d)\n",
    "        tmp_df[\"return\"] = tmp_df.apply(get_return_bonds,axis=1)   \n",
    "        \n",
    "        # Get the current yield \n",
    "        y0 = tmp_df[\"Yield\"].iloc[0]\n",
    "        \n",
    "        # Add the results to the corresponding DataFrames\n",
    "        possible_returns[t] = tmp_df[\"return\"][:-d]\n",
    "        possible_zero_rate[t] = y0 * np.exp(tmp_df[\"return\"][:-d])\n",
    "        possible_df[t] = np.exp(- possible_zero_rate[t] * t)\n",
    "\n",
    "    # For all tenors\n",
    "    for i in range(len(pmt_df[\"t\"])):\n",
    "        t = pmt_df[\"t\"].iloc[i]\n",
    "        cf = pmt_df[\"cf\"].iloc[i]\n",
    "        \n",
    "        # Add the PV\n",
    "        possible_prices[\"Price\"] +=  cf * possible_df[t]\n",
    "    \n",
    "    # Compute P0\n",
    "    P0 = possible_prices[\"Price\"].iloc[0]\n",
    "    \n",
    "    k = int((len(possible_prices))*(1-p/100))\n",
    "    \n",
    "    return abs(possible_prices[\"Price\"].nsmallest(k).values[-1]-P0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VaR_cfm_bonds(\n",
    "    zero_rate_data,today, mat, FV, coupon_rate, coupon_freq, d, p\n",
    "):     \n",
    "    \"\"\" Returns the d-day p% VaR of a bond using Cash Flow Mapping (CFM).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    zero_rate_data : pandas.DataFrame\n",
    "        the historical zero rates for the benchmark tenors\n",
    "    today : datetime\n",
    "        the date today in '%Y-%m-%d' format\n",
    "    mat : datetime\n",
    "        the maturity date in '%Y-%m-%d' format\n",
    "    FV : float\n",
    "        the face value or par value, FV in units of currency\n",
    "    coupon_rate : float\n",
    "        (annual) coupon_rate\n",
    "    coupon_freq : int\n",
    "        the number of times coupon interest is paid in one year\n",
    "    d : int\n",
    "        the value to be used in calculating the d-day VaR (e.g. 1-day, 5-day)\n",
    "    p : int\n",
    "        the value to be used in calculating the p% VaR (e.g. 99, 95)\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        d-day p% VaR of a bond using Cash Flow Mapping    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create empty dictionary for renaming\n",
    "    rename_dict = {}\n",
    "    \n",
    "    # Create empty list for storing tenors of benchmark\n",
    "    tenor = []\n",
    "    \n",
    "    # Process the columns\n",
    "    for i in zero_rate_data.columns:\n",
    "        if len(str(i).split(\"-\")) == 2:\n",
    "            [a,b] = str(i).split(\"-\")\n",
    "            a = int(a)\n",
    "            if b == \"Month\":\n",
    "                rename_dict[i] = a/12\n",
    "                tenor.append(a/12)\n",
    "            elif b == \"Year\":\n",
    "                rename_dict[i] = a\n",
    "                tenor.append(a)\n",
    "                \n",
    "    # Convert the labels to floats\n",
    "    zero_rate_data.rename(rename_dict,axis=1,inplace=True)\n",
    "        \n",
    "    # Compute the coupon\n",
    "    coupon = (coupon_rate * FV) / coupon_freq\n",
    "    \n",
    "    today = dt.datetime.strptime(today, '%Y-%m-%d')\n",
    "    mat_date = dt.datetime.strptime(mat, '%Y-%m-%d') \n",
    "    \n",
    "    # Create list of coupon dates\n",
    "    # Currently only works for annual coupon payments\n",
    "    coupon_dates = []\n",
    "    coupon_date = mat_date\n",
    "    \n",
    "    while today < coupon_date:\n",
    "        if coupon_freq==1:# annual\n",
    "            coupon_dates.append(coupon_date)\n",
    "            coupon_date = coupon_date.replace(year=coupon_date.year - 1) \n",
    "\n",
    "        else:\n",
    "            coupon_dates.append(coupon_date)\n",
    "            coupon_date = coupon_date - relativedelta(months=int(12/coupon_freq))\n",
    "\n",
    "    # Arrange coupon_dates in increasing order of dates\n",
    "    coupon_dates = coupon_dates[::-1]\n",
    "    \n",
    "    # Create a dataframe of payment schedules\n",
    "    pmt_df = pd.DataFrame({'coupon_dates':coupon_dates})\n",
    "    \n",
    "    pmt_df[\"t\"] = [get_tenor(today, t) for t in pmt_df['coupon_dates']]\n",
    "    \n",
    "    pmt_df[\"cf\"] = coupon\n",
    "    pmt_df.loc[len(coupon_dates)-1,\"cf\"] += FV\n",
    "    \n",
    "    # Generate the DataFrame of N-day returns\n",
    "    returns_df = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"][:-d]})\n",
    "    \n",
    "    for t in zero_rate_data.columns:\n",
    "        if t == \"Date\":\n",
    "            continue\n",
    "        \n",
    "        # Create a temporary DataFrame\n",
    "        tmp_df = pd.DataFrame({\"Date\":zero_rate_data[\"Date\"]})\n",
    "        \n",
    "        # Copy the Yield for tenor t\n",
    "        tmp_df[\"Yield\"] = zero_rate_data[t]\n",
    "        \n",
    "        # Get the returns\n",
    "        tmp_df[\"previous\"] = tmp_df[\"Yield\"].shift(-d)\n",
    "        tmp_df[\"return\"] = tmp_df.apply(get_return_bonds,axis=1)   \n",
    "                \n",
    "        # Add the results to the corresponding DataFrames\n",
    "        returns_df[t] = tmp_df[\"return\"][:-d]    \n",
    "    \n",
    "    # Output df\n",
    "    tmp = returns_df.copy()\n",
    "    tmp.rename({1/12:round(1/12,3)},axis=1,inplace=True)\n",
    "    \n",
    "    # Compute the correlation matrix\n",
    "    corr_mat = returns_df.corr()\n",
    "    print(\"The correlation matrix is:\")\n",
    "    print(round(tmp.corr(),2))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Compute the standard deviation of each tenor\n",
    "    std_lst = returns_df.std()\n",
    "    print(\"The volatilities are:\")\n",
    "    print(round(tmp.std(),2))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Compute the covariance matrix\n",
    "    SIGMA = returns_df.cov()\n",
    "        \n",
    "    # Initialize the cash flow map\n",
    "    cf_map = pd.DataFrame(data=[np.zeros(len(tenor))],columns=tenor)   \n",
    "    \n",
    "    # Map each cash flow\n",
    "    for i in range(len(pmt_df[\"t\"])):\n",
    "        cf = pmt_df[\"cf\"].iloc[i]\n",
    "        t = pmt_df[\"t\"].iloc[i]\n",
    "        idx = 0\n",
    "        \n",
    "        # Get the two nearest tenors from the benchmark data\n",
    "        while tenor[idx] < t and idx < len(tenor):\n",
    "            idx += 1\n",
    "        \n",
    "        # Assign the variables\n",
    "        t1 = tenor[idx-1]\n",
    "        t2 = tenor[idx]\n",
    "        sigma1 = std_lst.loc[t1]\n",
    "        sigma2 = std_lst.loc[t2]\n",
    "        rho = corr_mat.loc[t1,t2]\n",
    "        sigma = linear_interp(t,[t1,t2],[sigma1,sigma2])\n",
    "        y0 = linear_interp(t,[t1,t2],[zero_rate_data[t1].iloc[0],zero_rate_data[t2].iloc[0]])\n",
    "\n",
    "        # Compute alpha1 and alpha2  \n",
    "        A = sigma1**2 + sigma2**2 - 2*rho*sigma1*sigma2\n",
    "        B = 2*rho*sigma1*sigma2 - 2*sigma2**2\n",
    "        C = sigma2**2 - sigma**2\n",
    "        \n",
    "        alpha1 = (-B + np.sqrt(B**2 - 4*A*C)) / (2*A)\n",
    "        if (alpha1 > 1) or (alpha1 < 0):\n",
    "            alpha1 = (-B - np.sqrt(B**2 - 4*A*C)) / (2*A)\n",
    "            \n",
    "        alpha2 = 1 - alpha1\n",
    "        \n",
    "        print(\"For cash flow \"+str(int(i+1))+\" worth \"+str(round(cf,2))+\", the alphas are: \"+str(round(alpha1,2))+\" and \"+str(round(alpha2,2))+\".\")\n",
    "        \n",
    "        # Add the values to the tenor\n",
    "        cf_map[t1] += alpha1 * cf * np.exp(- zero_rate_data[t1].iloc[0] * t1 )\n",
    "        cf_map[t2] += alpha2 * cf * np.exp(- zero_rate_data[t2].iloc[0] * t2 )\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"The present value of the cash flows are:\")\n",
    "    print(round(cf_map,2))\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    # Compute the standard deviation\n",
    "    alpha = cf_map.copy();\n",
    "    \n",
    "    sigma = np.sqrt(np.dot(cf_map,np.dot(SIGMA,cf_map.T)))\n",
    "    quantile = NormalDist().inv_cdf(p/100)\n",
    "    \n",
    "    return sigma[0][0] * quantile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Question A\n",
    "Assume that today is April 23, 2021. Suppose market risk metrics are requested for **Portfolio A** consisting of long positions on the following four bonds:\n",
    "\n",
    "1. Roquefort Bond\n",
    "    - A corporate bond with Php 1,000,000 face value, 8% p.a. coupon rate that pays interest annually, with maturity date on December 31, 2026.\n",
    "    \n",
    "2. Camembert Bond\n",
    "    - A corporate bond  with Php 1,000,000 face value, 7.5% p.a. coupon rate that pays interest semiannually, with maturity date on June 1, 2022.\n",
    "\n",
    "3. Feta Bond\n",
    "    - A T-bond with Php 1,000,000 face value, 6% p.a. coupon rate that pays interest quarterly, with maturity date on January 15, 2035.\n",
    "    \n",
    "4. Gouda Bond\n",
    "    - A zero-coupon bond with Php 1,000,000 face value, with maturity date on September 28, 2030.\n",
    "    \n",
    "\n",
    "The historical **continuously-compounded** market yields for the four bonds can be found in the `portfolio_a_yield_data.csv` file. Assume an actual/360 day-count convention. \n",
    "\n",
    "\n",
    "1. Determine the dollar duration (DV01) for each bond.\n",
    "2. Calculate the portfolio's undiversified and diversified 10-day 99% VaR using Delta-Normal Approach. What is the benefit of diversification?   \n",
    "4. Consider the subportfolio consisting only of Roquefort Bond and Camembert Bond. Assume that the ten-day bond volatilities and the covariance of their returns follow exponentially weighted moving average models with the following decay parameters:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "           Data\n",
    "        </td>\n",
    "        <td>\n",
    "            Roquefort\n",
    "        </td>\n",
    "        <td>\n",
    "            Camembert\n",
    "        </td>\n",
    "        <td>\n",
    "            Covariance\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            Decay Parameter\n",
    "        </td>\n",
    "        <td>\n",
    "            0.85\n",
    "        </td>\n",
    "        <td>\n",
    "            0.80\n",
    "        </td>\n",
    "        <td>\n",
    "            0.975\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "   Determine the undiversified and diversified 10-day 99\\% VaR for the subportfolio. What is the benefit of diversification?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DV01 for Roquefort is Php 484.41.\n",
      "The DV01 for Camembert is Php 109.67.\n",
      "The DV01 for Feta is Php 923.93.\n",
      "The DV01 for Gouda is Php 720.2.\n",
      "\n",
      "The Undiversified 10-day 99% VaR is Php 47810.4.\n",
      "The Diversified 10-day 99% VaR is Php 46164.02.\n",
      "The benefit of diversification is Php 1646.38.\n",
      "\n",
      "The Undiversified 10-day 99% VaR of the subportfolio is Php 10717.56.\n",
      "The Diversified 10-day 99% VaR of the subportfolio is Php 10295.13.\n",
      "The benefit of diversification of the subportfolio is Php 422.43.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ateneobsamf2021/ma195l2/main/data/Project1/portfolio_a_yield_data.csv\")\n",
    "df_lst = []\n",
    "N_lst = []\n",
    "mat = [\"2026-12-31\",\"2022-06-01\",\"2035-01-15\",\"2030-09-28\"]\n",
    "FV = [1000000,1000000,1000000,1000000]\n",
    "coupon_rate = [0.08,0.075,0.06,0]\n",
    "coupon_freq = [1,2,4,1]\n",
    "today=\"2021-04-23\"\n",
    "\n",
    "for idx in range(len(df.columns)):\n",
    "    bond = df.columns[idx]\n",
    "    if bond != \"Date\":\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df.rename({bond:\"Yield\"},axis=1,inplace=True)\n",
    "        df_lst.append(tmp_df)\n",
    "        y = tmp_df[\"Yield\"].iloc[0]/100\n",
    "        DV01 = get_bond_info(today, mat[idx-1], FV[idx-1], coupon_rate[idx-1], coupon_freq[idx-1], y)[2]\n",
    "        N_lst.append(DV01)\n",
    "        print(f\"The DV01 for {bond} is Php {round(DV01,2)}.\")\n",
    "        \n",
    "undiv = undiversified_VaR_delta_normal_bonds(df_lst, N_lst, 10, 99)\n",
    "div = diversified_VaR_delta_normal_bonds(df_lst, N_lst, 10, 99)\n",
    "benefit = undiv-div\n",
    "print(f\"The Undiversified 10-day 99% VaR is Php {round(undiv,2)}.\")\n",
    "print(f\"The Diversified 10-day 99% VaR is Php {round(div,2)}.\")\n",
    "print(f\"The benefit of diversification is Php {round(benefit,2)}.\")\n",
    "\n",
    "undiv = undiversified_VaR_delta_normal_bonds(df_lst[:2], N_lst[:2], 10, 99,ewma_par_lst=[0.85,0.8])\n",
    "div = diversified_VaR_delta_normal_bonds(df_lst[:2], N_lst[:2], 10, 99,ewma_par_lst=[0.85,0.8],covar_ewma_par_mat=[[0,0.975],[0.975,0]])\n",
    "benefit = undiv-div\n",
    "print(f\"The Undiversified 10-day 99% VaR of the subportfolio is Php {round(undiv,2)}.\")\n",
    "print(f\"The Diversified 10-day 99% VaR of the subportfolio is Php {round(div,2)}.\")\n",
    "print(f\"The benefit of diversification of the subportfolio is Php {round(benefit,2)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question B\n",
    "Assume that today is April 23, 2021. Suppose market risk metrics are requested for **Portfolio B** consisting solely of a peso-denominated bond corporate bond with a principal of Php 10,000,000 and with maturity date on December 31, 2024. Suppose that the bond provides a coupon of 10% per annum payable semiannually.\n",
    "\n",
    "The historical continuously-compounded zero rates for benchmark tenors are provided in the `portfolio_b_zero_rate_data.csv` file.\n",
    "\n",
    "### Historical Simulation Approach\n",
    "1. Generate possible zero rates 10 days from now for the relevant tenors and determine the portfolio's 10-day 99% VaR using the historical simulation approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The portfolio's 10-day 99% VaR is Php 273088.82.\n"
     ]
    }
   ],
   "source": [
    "zero_rates = pd.read_csv(\"https://raw.githubusercontent.com/ateneobsamf2021/ma195l2/main/data/Project1/portfolio_b_zero_rate_data.csv\")\n",
    "\n",
    "hs = VaR_hs_bonds(\n",
    "    zero_rates,\n",
    "    today=\"2021-04-23\", \n",
    "    mat=\"2024-12-31\", \n",
    "    FV=10000000, \n",
    "    coupon_rate=0.10, \n",
    "    coupon_freq=2,\n",
    "    d = 10, \n",
    "    p = 99\n",
    ")\n",
    "\n",
    "print(f\"The portfolio's 10-day 99% VaR is Php {round(hs,2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Flow Mapping\n",
    "1. Estimate the volatilities and correlations of zero-coupon bonds maturing on the benchmark tenors using the given data. Print out the volatilities and the correlation matrix.\n",
    "2. Map the portfolio's cash flows to the benchmark tenors/standard buckets. Print out the weight $\\alpha_i$ for each cash flow.\n",
    "2. Print out the present values of the mapped cash flows at each benchmark tenor/standard bucket.\n",
    "3. Determine the portfolio's 10-day 99% VaR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation matrix is:\n",
      "       0.083  0.25   0.5     1     2     3     4     5\n",
      "0.083   1.00  0.27  0.13  0.04 -0.01  0.01 -0.06 -0.11\n",
      "0.25    0.27  1.00  0.42  0.25  0.30  0.26  0.23  0.21\n",
      "0.5     0.13  0.42  1.00  0.50  0.49  0.36  0.50  0.42\n",
      "1       0.04  0.25  0.50  1.00  0.37  0.29  0.30  0.37\n",
      "2      -0.01  0.30  0.49  0.37  1.00  0.70  0.64  0.76\n",
      "3       0.01  0.26  0.36  0.29  0.70  1.00  0.60  0.63\n",
      "4      -0.06  0.23  0.50  0.30  0.64  0.60  1.00  0.69\n",
      "5      -0.11  0.21  0.42  0.37  0.76  0.63  0.69  1.00\n",
      "\n",
      "The volatilities are:\n",
      "0.083    0.11\n",
      "0.25     0.07\n",
      "0.5      0.06\n",
      "1        0.06\n",
      "2        0.05\n",
      "3        0.05\n",
      "4        0.07\n",
      "5        0.07\n",
      "dtype: float64\n",
      "\n",
      "For cash flow 1 worth 500000.0, the alphas are: 0.71 and 0.29.\n",
      "For cash flow 2 worth 500000.0, the alphas are: 0.07 and 0.93.\n",
      "For cash flow 3 worth 500000.0, the alphas are: 0.96 and 0.04.\n",
      "For cash flow 4 worth 500000.0, the alphas are: 0.84 and 0.16.\n",
      "For cash flow 5 worth 500000.0, the alphas are: 0.98 and 0.02.\n",
      "For cash flow 6 worth 500000.0, the alphas are: 0.93 and 0.07.\n",
      "For cash flow 7 worth 500000.0, the alphas are: 0.39 and 0.61.\n",
      "For cash flow 8 worth 10500000.0, the alphas are: 0.11 and 0.89.\n",
      "\n",
      "The present value of the cash flows are:\n",
      "    0.083333   0.250000  0.500000    1.000000   2.000000    3.000000  \\\n",
      "0  353353.87  142915.16  32612.55  1282657.47  939655.51  1189336.75   \n",
      "\n",
      "     4.000000  5.000000  \n",
      "0  7641195.44       0.0  \n",
      "\n",
      "The portfolio's 10-day 99% VaR is Php 1458365.2.\n"
     ]
    }
   ],
   "source": [
    "zero_rates = pd.read_csv(\"https://raw.githubusercontent.com/ateneobsamf2021/ma195l2/main/data/Project1/portfolio_b_zero_rate_data.csv\")\n",
    "\n",
    "hs = VaR_cfm_bonds(\n",
    "    zero_rates,\n",
    "    today=\"2021-04-23\", \n",
    "    mat=\"2024-12-31\", \n",
    "    FV=10000000, \n",
    "    coupon_rate=0.10, \n",
    "    coupon_freq=2,\n",
    "    d = 10, \n",
    "    p = 99\n",
    ")\n",
    "\n",
    "print(f\"The portfolio's 10-day 99% VaR is Php {round(hs,2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question A\n",
    "\n",
    "Consider **Portfolio A** and its undiversified 10-day 99% VaR which you calculated using Delta-Normal Approach in Part 2.\n",
    "\n",
    "Which of the four bonds in the fixed-income portfolio has the highest contribution to the undiversified 10-day 99% VaR? Why? Compare the individual VaRs and determine which factors and bond features led to the bond's high VaR contribution. Explore and discuss the effect of these factors and features to the resulting VaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roquefort: DV01 - 484.41, VaR - 11093.89\n",
      "Camembert: DV01 - 109.67, VaR - 813.88\n",
      "Feta: DV01 - 923.93, VaR - 20763.78\n",
      "Gouda: DV01 - 720.2, VaR - 15138.85\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ateneobsamf2021/ma195l2/main/data/Project1/portfolio_a_yield_data.csv\")\n",
    "mat = [\"2026-12-31\",\"2022-06-01\",\"2035-01-15\",\"2030-09-28\"]\n",
    "FV = [1000000,1000000,1000000,1000000]\n",
    "coupon_rate = [0.08,0.075,0.06,0]\n",
    "coupon_freq = [1,2,4,1]\n",
    "today=\"2021-04-23\"\n",
    "\n",
    "for idx in range(len(df.columns)):\n",
    "    bond = df.columns[idx]\n",
    "    if bond != \"Date\":\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df.rename({bond:\"Yield\"}, axis=1, inplace=True)\n",
    "        y = tmp_df[\"Yield\"].iloc[0]/100\n",
    "        DV01 = get_bond_info(today, mat[idx-1], FV[idx-1], coupon_rate[idx-1], coupon_freq[idx-1], y)[2]\n",
    "        VaR = undiversified_VaR_delta_normal_bonds([tmp_df], [DV01], 10, 99)\n",
    "        print(f\"{bond}: DV01 - {round(DV01,2)}, VaR - {round(VaR,2)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feta has the largest VaR out of the four bonds due to its longer maturity date of January 15, 2035. This means that a small change in yield can have a large effect on the value of the bond since more cash flow are affected by the change in yield. This effect is also compounded (continuously) thus it has a larger impact on the price. In fact, the DV01 of Feta is the largest meaning a 0.01% change in its yield has the greatest change in value.\n",
    "\n",
    "Gouda has the second largest VaR out of the four bonds since it is a zero rate bond. All of the principal will be returned at maturity so a small change in yield also changes the value by a lot.\n",
    "\n",
    "Therefore, when comparing the VaR of different types of bonds, longer maturity and zero coupon bonds will have a larger VaR on average, assuming the same par value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
